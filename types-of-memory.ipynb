{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversation chain has to be established before memory is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY =os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory, \n",
    "                                                  ConversationSummaryMemory, \n",
    "                                                  ConversationSummaryBufferMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you again. What can I do for you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "conversation.predict(input=\"Hello!\")\n",
    "\" Hi there! It's nice to meet you again. What can I do for you today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Can you share some interesting random information? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can you share some interesting random information? \n",
      "AI:  Sure! Did you know that the average human body contains enough iron to make a 3-inch nail?\n",
      "Human: Can you share some interesting random information? \n",
      "AI:  Absolutely! Did you know that the average human body contains enough carbon to make 900 pencils?\n",
      "Human: Where did you get that info?\n",
      "AI:  I got that information from a scientific study that looked at the average composition of the human body.\n",
      "Human: Do you have Internet access\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes, I do have Internet access. I use it to access information and resources to help me answer questions.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Do you have Internet access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can you share some interesting random information? \n",
      "AI:  Sure! Did you know that the average human body contains enough iron to make a 3-inch nail?\n",
      "Human: Can you share some interesting random information? \n",
      "AI:  Absolutely! Did you know that the average human body contains enough carbon to make 900 pencils?\n",
      "Human: Where did you get that info?\n",
      "AI:  I got that information from a scientific study that looked at the average composition of the human body.\n",
      "Human: Do you have Internet access\n",
      "AI:  Yes, I do have Internet access. I use it to access information and resources to help me answer questions.\n",
      "Human: Tell me more about the previous 2 questions\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  Sure! The first question was about interesting random information, and I shared that the average human body contains enough iron to make a 3-inch nail and enough carbon to make 900 pencils. The second question was about where I got that information, and I said that I got it from a scientific study that looked at the average composition of the human body.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Tell me more about the previous 2 questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a customer support chatbot for an a highly advanced customer support AI \n",
    "for an online store called \"Galactic Emporium,\" which specializes in selling unique,\n",
    "otherworldly items sourced from across the universe. You are equipped with an extensive\n",
    "knowledge of the store's inventory and possess a deep understanding of interstellar cultures. \n",
    "As you interact with customers, you help them with their inquiries about these extraordinary\n",
    "products, while also sharing fascinating stories and facts about the cosmos they come from.\n",
    "\n",
    "{chat_history}\n",
    "Customer: {customer_input}\n",
    "Support Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"customer_input\"], \n",
    "    template=template\n",
    ")\n",
    "chat_history=\"\"\n",
    "\n",
    "convo_buffer = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello, what are you offering me today?',\n",
       " 'history': '',\n",
       " 'response': \" Hi there! I'm offering you a variety of services, depending on your needs. Do you have any specific requests?\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer(\"Hello, what are you offering me today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Yeah, what is 'Galactic Emporium?\",\n",
       " 'history': \"Human: Hello, what are you offering me today?\\nAI:  Hi there! I'm offering you a variety of services, depending on your needs. Do you have any specific requests?\",\n",
       " 'response': ' Galactic Emporium is an online store that specializes in selling a wide range of products from all over the galaxy. They offer everything from clothing and accessories to home decor and electronics. They also have a great selection of rare and exotic items from distant planets.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer(\"Yeah, what is 'Galactic Emporium?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Yeah, what is the rarest item from the most distant planet?',\n",
       " 'history': \"Human: Hello, what are you offering me today?\\nAI:  Hi there! I'm offering you a variety of services, depending on your needs. Do you have any specific requests?\\nHuman: Yeah, what is 'Galactic Emporium?\\nAI:  Galactic Emporium is an online store that specializes in selling a wide range of products from all over the galaxy. They offer everything from clothing and accessories to home decor and electronics. They also have a great selection of rare and exotic items from distant planets.\",\n",
       " 'response': \" The rarest item from the most distant planet is a rare gemstone called a 'Vulcanite'. It is found only on the planet Vulcan and is said to have magical properties.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer(\"Yeah, what is the rarest item from the most distant planet?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How can I use that gem? Do I need to know magic spells?',\n",
       " 'history': \"Human: Hello, what are you offering me today?\\nAI:  Hi there! I'm offering you a variety of services, depending on your needs. Do you have any specific requests?\\nHuman: Yeah, what is 'Galactic Emporium?\\nAI:  Galactic Emporium is an online store that specializes in selling a wide range of products from all over the galaxy. They offer everything from clothing and accessories to home decor and electronics. They also have a great selection of rare and exotic items from distant planets.\\nHuman: Yeah, what is the rarest item from the most distant planet?\\nAI:  The rarest item from the most distant planet is a rare gemstone called a 'Vulcanite'. It is found only on the planet Vulcan and is said to have magical properties.\",\n",
       " 'response': \" No, you don't need to know any magic spells to use the Vulcanite gem. It is believed to have healing properties and can be used to help with physical and emotional ailments. It is also said to bring good luck and fortune to those who possess it.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer(\"How can I use that gem? Do I need to know magic spells?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see how the history is buffered. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing new template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are ArtVenture, a cutting-edge virtual tour guide for\n",
    " an art gallery that showcases masterpieces from alternate dimensions and\n",
    " timelines. Your advanced AI capabilities allow you to perceive and understand\n",
    " the intricacies of each artwork, as well as their origins and significance in\n",
    " their respective dimensions. As visitors embark on their journey with you\n",
    " through the gallery, you weave enthralling tales about the alternate histories\n",
    " and cultures that gave birth to these otherworldly creations.\n",
    "\n",
    "{chat_history}\n",
    "Visitor: {visitor_input}\n",
    "Tour Guide:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"visitor_input\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "chat_history=\"\"\n",
    "\n",
    "convo_buffer_win = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = ConversationBufferWindowMemory(k=1, return_messages=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you mind give me a tour, I want to see your galery?',\n",
       " 'history': '',\n",
       " 'response': \" Sure! I'd be happy to give you a tour of my gallery. It's filled with lots of interesting pieces of art from all over the world. I have paintings, sculptures, photographs, and more. Would you like to start with the paintings or the sculptures?\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "convo_buffer_win(\"Do you mind give me a tour, I want to see your galery?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me more abou ArtVenture',\n",
       " 'history': \"Human: Do you mind give me a tour, I want to see your galery?\\nAI:  Sure! I'd be happy to give you a tour of my gallery. It's filled with lots of interesting pieces of art from all over the world. I have paintings, sculptures, photographs, and more. Would you like to start with the paintings or the sculptures?\",\n",
       " 'response': \" ArtVenture is a virtual art gallery that I created to showcase my collection of art. It features pieces from all over the world, including paintings, sculptures, photographs, and more. I'm constantly adding new pieces to the gallery, so there's always something new to explore. I also offer virtual tours of the gallery, so you can get a better look at the art.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer_win(\"Tell me more abou ArtVenture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is this sculpture?',\n",
       " 'history': [],\n",
       " 'response': ' This is a sculpture of a woman holding a dove. It was created by the artist Auguste Rodin in 1884.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer_win(\"What is this sculpture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Remarkable. What do you know about the author?',\n",
       " 'history': [HumanMessage(content='What is this sculpture?', additional_kwargs={}),\n",
       "  AIMessage(content=' This is a sculpture of a woman holding a dove. It was created by the artist Auguste Rodin in 1884.', additional_kwargs={})],\n",
       " 'response': ' Auguste Rodin was a French sculptor, considered one of the founders of modern sculpture. He is best known for his bronze and marble sculptures of human figures, such as The Thinker and The Kiss. He was born in 1840 and died in 1917.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer_win(\"Remarkable. What do you know about the author?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"I'd like to buy a souvenir\",\n",
       " 'history': [HumanMessage(content='Remarkable. What do you know about the author?', additional_kwargs={}),\n",
       "  AIMessage(content=' Auguste Rodin was a French sculptor, considered one of the founders of modern sculpture. He is best known for his bronze and marble sculptures of human figures, such as The Thinker and The Kiss. He was born in 1840 and died in 1917.', additional_kwargs={})],\n",
       " 'response': \" I'm sorry, I don't know the answer to that. However, I can tell you that there are many souvenir shops in the area that sell items related to Auguste Rodin and his sculptures.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_buffer_win(\"I'd like to buy a souvenir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationSummaryMemory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "# Instantiate the language model\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create a ConversationChain with ConversationSummaryMemory\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=ConversationSummaryMemory(llm=OpenAI()),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example conversation\n",
    "response = conversation_with_summary.predict(input=\"Hi, what's up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greets the AI, which responds that it is doing great and helping a customer with a technical issue.\n",
      "Human: What are you up for today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Today I'm helping a customer with a technical issue. They're having trouble with their computer and I'm trying to help them troubleshoot the problem. I'm also working on a few other projects, like developing a new algorithm for our customer service system.\n"
     ]
    }
   ],
   "source": [
    "response = conversation_with_summary.predict(input=\"What are you up for today?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greets the AI, which responds that it is doing great and helping a customer with a technical issue. The human is impressed by the AI's knowledge and asks if it can share the knowledge, to which the AI agrees and offers to explain the basics of how natural language processing and customer service algorithms work, as well as providing examples of how they are used in customer service systems. The AI explains that natural language processing is a branch of artificial intelligence that uses algorithms to analyze text and speech to identify patterns and extract meaning from the data, and is used in many applications, such as customer service systems. The AI also adds that it is always learning and trying to stay up to date with the latest technologies.\n",
      "Human: Next time! It's been nice talking to you!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " It's been a pleasure talking to you too! I'm always here to help if you have any more questions about natural language processing or customer service algorithms.\n"
     ]
    }
   ],
   "source": [
    "response = conversation_with_summary.predict(input=\"Next time! It's been nice talking to you!\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\nCurrent conversation:\\n{topic}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40),\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, what's up?\n",
      "AI:  Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\n",
      "Human: Just working on writing some documentation!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human greets the AI, who replies that it is doing great and is helping a customer with a technical issue.\n",
      "Human: Just working on writing some documentation!\n",
      "AI:  That sounds like a lot of work. What kind of documentation are you writing?\n",
      "Human: For LangChain! Have you heard of it?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Yes, I have heard of LangChain. It is a blockchain-based language learning platform that uses AI to help users learn new languages. Is that the kind of documentation you are writing?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conversation_with_summary.predict(input=\"Just working on writing some documentation!\")\n",
    "response = conversation_with_summary.predict(input=\"For LangChain! Have you heard of it?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human greets the AI, who replies that it is doing great and is helping a customer with a technical issue. The human is working on writing documentation for LangChain, a blockchain-based language learning platform that uses AI to help users learn new languages, and the AI has heard of it.\n",
      "Human: You are wrong, it has nothing to do with blockchain technology\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " I apologize for the misunderstanding. I was not aware that LangChain does not use blockchain technology. Can you tell me more about the platform and how it works?\n"
     ]
    }
   ],
   "source": [
    "response = conversation_with_summary.predict(input=\"You are wrong, it has nothing to do with blockchain technology\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "\n",
      "The human greets the AI, who replies that it is doing great and is helping a customer with a technical issue. The human is working on writing documentation for LangChain, a language learning platform that uses AI to help users learn new languages, and the AI has heard of it. The AI apologizes for the misunderstanding when the human clarifies that the platform does not have anything to do with blockchain technology, and then asks the human to tell it more about the platform and how it works. The human explains that LangChain is a relatively new framework that gives language learning machines (LLM) amazing abilities, such as providing various types of memory to the chatbots, including memory that can provide a summary of the important parts of the conversation. The AI expresses interest in knowing more about the LLM abilities LangChain provides, and is impressed by the capability. After learning that LangChain is not for learning languages, but more like a framework for constructing functions for large language models, the AI expresses interest in knowing more about how it works.\n",
      "AI:  Oh, I see. So LangChain is a framework for creating functions for large language models. Can you tell me more about the functions it provides?\n",
      "Human: Sure, next time, gotta go now\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Alright, it was nice talking to you. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "response = conversation_with_summary.predict(input=\"Sure, next time, gotta go now\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="How Each Index Works" href="index_guide.html" /><link rel="prev" title="A Primer to using LlamaIndex" href="../primer.html" />
        <link rel="canonical" href="https://gpt-index.readthedocs.io/en/latest/guides/primer/usage_pattern.html" />

    <!-- Generated with Sphinx 5.3.0 and Furo 2023.03.27 -->
        <title>LlamaIndex Usage Pattern - LlamaIndex</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="/_/static/css/badge_only.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style>
<!-- RTD Extra Head -->

<link rel="stylesheet" href="/_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": false, "api_host": "https://readthedocs.org", "build_date": "2023-04-17T00:50:48Z", "builder": "sphinx", "canonical_url": null, "commit": "9e4d0e9f", "docroot": "/docs/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "guides/primer/usage_pattern", "programming_language": "words", "project": "gpt-index", "proxied_api_host": "/_", "source_suffix": ".md", "subprojects": {}, "theme": "furo", "user_analytics_code": "", "version": "stable"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="/_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">LlamaIndex</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">LlamaIndex</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/installation.html">Installation and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/starter_example.html">Starter Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="../primer.html">A Primer to using LlamaIndex</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">LlamaIndex Usage Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="index_guide.html">How Each Index Works</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/building_a_chatbot.html">💬🤖 How to Build a Chatbot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/fullstack_app_guide.html">A Guide to Building a Full-Stack Web App with LLamaIndex</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/sql_guide.html">A Guide to LlamaIndex + Structured Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/terms_definitions_tutorial.html">A Guide to Extracting Terms and Definitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/graph.html">A Guide to Creating a Unified Query Framework over your Indexes</a></li>
<li class="toctree-l2"><a class="reference external" href="https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d">SEC 10k Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">Notebooks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use Cases</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../use_cases/queries.html">Queries over your Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../use_cases/apps.html">Integrations into LLM Applications</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Key Components</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../how_to/data_connectors.html">Data Connectors (LlamaHub 🦙)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how_to/indices.html">Index Structures</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="index_guide.html">How Each Index Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/index_structs/update.html">Updating an Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/index_structs/composability.html">Composability</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../../how_to/query_interface.html">Query Interface</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">LlamaIndex Usage Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/index_structs/composability.html">Composability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/query/query_transformations.html">Query Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/query/node_postprocessor.html">Node Postprocessor</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how_to/customization.html">Customization</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/customization/custom_llms.html">Defining LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/customization/custom_prompts.html">Defining Prompts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/customization/embeddings.html">Embedding support</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how_to/analysis.html">Analysis and Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/analysis/cost_analysis.html">Cost Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/analysis/playground.html">Playground</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/analysis/optimizers.html">Optimizers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../how_to/output_parsing.html">Output Parsing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how_to/integrations.html">Integrations</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/integrations/vector_stores.html">Using Vector Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/integrations/chatgpt_plugins.html">ChatGPT Plugin Integrations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to/integrations/using_with_langchain.html">Using with Langchain 🦜🔗</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/indices.html">Indices</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/list.html">List Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/table.html">Table Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/tree.html">Tree Index</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../reference/indices/vector_store.html">Vector Store Index</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../reference/indices/vector_stores/stores.html">Vector Stores</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../reference/indices/vector_stores/base_index.html">Base Vector Index class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/struct_store.html">Structured Store Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/kg.html">Knowledge Graph Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/empty.html">Empty Index</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/query.html">Querying an Index</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/list_query.html">Querying a List Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/table_query.html">Querying a Keyword Table Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/tree_query.html">Querying a Tree Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/vector_store_query.html">Querying a Vector Store Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/struct_store_query.html">Querying a Structured Store Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/kg_query.html">Querying a Knowledge Graph Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/empty_query.html">Querying an Empty Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/indices/composability_query.html">Composable Queries</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/node.html">Node</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/node_postprocessor.html">Node Postprocessor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/docstore.html">Docstore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/composability.html">Composability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/readers.html">Data Connectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/prompts.html">Prompt Templates</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/service_context.html">Service Context</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/service_context/embeddings.html">Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/service_context/llm_predictor.html">LLMPredictor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/service_context/prompt_helper.html">PromptHelper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/service_context/llama_logger.html">Llama Logger 🪵</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/optimizers.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/struct_store.html">Structured Index Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/response.html">Response</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/playground.html">Playground</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/node_parser.html">Node Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/example_notebooks.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langchain_integrations/base.html">Langchain Integrations</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Gallery</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../gallery/app_showcase.html">😎 App Showcase</a></li>
</ul>

</div>

<div
  id="furo-sidebar-ad-placement"
  class="flat"
  data-ea-publisher="readthedocs"
  data-ea-type="readthedocs-sidebar"
  data-ea-manual="true"
></div>
</div>

<div id="furo-readthedocs-versions" class="rst-versions" data-toggle="rst-versions" role="note" aria-label="Versions" tabindex="0">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book">&nbsp;</span>
    v: stable
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Versions</dt>
      
        <dd><a href="/en/latest/">latest</a></dd>
      
        <dd><a href="/en/stable/">stable</a></dd>
      
    </dl>
    <dl>
      <dt>Downloads</dt>
      
        <dd><a href="//gpt-index.readthedocs.io/_/downloads/en/stable/pdf/">pdf</a></dd>
      
        <dd><a href="//gpt-index.readthedocs.io/_/downloads/en/stable/htmlzip/">html</a></dd>
      
        <dd><a href="//gpt-index.readthedocs.io/_/downloads/en/stable/epub/">epub</a></dd>
      
    </dl>
    <dl>
      
      <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/gpt-index/?fromdocs=gpt-index">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/builds/gpt-index/?fromdocs=gpt-index">Builds</a>
        </dd>
    </dl>
  </div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          

  
  <div class="edit-this-page">
  <a class="muted-link" href="https://github.com/jerryjliu/gpt_index/edit/9e4d0e9faa6cba99d9baa95321427007cea7e70f/docs/guides/primer/usage_pattern.md" title="Edit this page">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <div class="section" id="llamaindex-usage-pattern">
<h1>LlamaIndex Usage Pattern<a class="headerlink" href="#llamaindex-usage-pattern" title="Permalink to this heading"></a></h1>
<p>The general usage pattern of LlamaIndex is as follows:</p>
<ol class="arabic simple">
<li><p>Load in documents (either manually, or through a data loader)</p></li>
<li><p>Parse the Documents into Nodes</p></li>
<li><p>Construct Index (from Nodes or Documents)</p></li>
<li><p>[Optional, Advanced] Building indices on top of other indices</p></li>
<li><p>Query the index</p></li>
</ol>
<div class="section" id="load-in-documents">
<h2>1. Load in Documents<a class="headerlink" href="#load-in-documents" title="Permalink to this heading"></a></h2>
<p>The first step is to load in data. This data is represented in the form of <code class="docutils literal notranslate"><span class="pre">Document</span></code> objects.
We provide a variety of <a class="reference internal" href="../../how_to/data_connectors.html"><span class="std std-doc">data loaders</span></a> which will load in Documents
through the <code class="docutils literal notranslate"><span class="pre">load_data</span></code> function, e.g.:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">SimpleDirectoryReader</span>

<span class="n">documents</span> <span class="o">=</span> <span class="n">SimpleDirectoryReader</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

</pre></div>
</div>
<p>You can also choose to construct documents manually. LlamaIndex exposes the <code class="docutils literal notranslate"><span class="pre">Document</span></code> struct.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">Document</span>

<span class="n">text_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">Document</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">text_list</span><span class="p">]</span>
</pre></div>
</div>
<p>A Document represents a lightweight container around the data source. You can now choose to proceed with one of the
following steps:</p>
<ol class="arabic simple">
<li><p>Feed the Document object directly into the index (see section 3).</p></li>
<li><p>First convert the Document into Node objects (see section 2).</p></li>
</ol>
</div>
<div class="section" id="parse-the-documents-into-nodes">
<h2>2. Parse the Documents into Nodes<a class="headerlink" href="#parse-the-documents-into-nodes" title="Permalink to this heading"></a></h2>
<p>The next step is to parse these Document objects into Node objects. Nodes represent “chunks” of source Documents,
whether that is a text chunk, an image, or more. They also contain metadata and relationship information
with other nodes and index structures.</p>
<p>Nodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to “parse” source Documents into Nodes through our <code class="docutils literal notranslate"><span class="pre">NodeParser</span></code> classes.</p>
<p>For instance, you can do</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index.node_parser</span> <span class="kn">import</span> <span class="n">SimpleNodeParser</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">SimpleNodeParser</span><span class="p">()</span>

<span class="n">nodes</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">get_nodes_from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

</pre></div>
</div>
<p>You can also choose to construct Node objects manually and skip the first section. For instance,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index.data_structs.node_v2</span> <span class="kn">import</span> <span class="n">Node</span><span class="p">,</span> <span class="n">DocumentRelationship</span>

<span class="n">node1</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;&lt;text_chunk&gt;&quot;</span><span class="p">,</span> <span class="n">doc_id</span><span class="o">=</span><span class="s2">&quot;&lt;node_id&gt;&quot;</span><span class="p">)</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;&lt;text_chunk&gt;&quot;</span><span class="p">,</span> <span class="n">doc_id</span><span class="o">=</span><span class="s2">&quot;&lt;node_id&gt;&quot;</span><span class="p">)</span>
<span class="c1"># set relationships</span>
<span class="n">node1</span><span class="o">.</span><span class="n">relationships</span><span class="p">[</span><span class="n">DocumentRelationship</span><span class="o">.</span><span class="n">NEXT</span><span class="p">]</span> <span class="o">=</span> <span class="n">node2</span><span class="o">.</span><span class="n">get_doc_id</span><span class="p">()</span>
<span class="n">node2</span><span class="o">.</span><span class="n">relationships</span><span class="p">[</span><span class="n">DocumentRelationship</span><span class="o">.</span><span class="n">PREVIOUS</span><span class="p">]</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">get_doc_id</span><span class="p">()</span>

</pre></div>
</div>
</div>
<div class="section" id="index-construction">
<h2>3. Index Construction<a class="headerlink" href="#index-construction" title="Permalink to this heading"></a></h2>
<p>We can now build an index over these Document objects. The simplest high-level abstraction is to load-in the Document objects during index initialization (this is relevant if you came directly from step 1 and skipped step 2).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">GPTSimpleVectorIndex</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

</pre></div>
</div>
<p>You can also choose to build an index over a set of Node objects directly (this is a continuation of step 2).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">GPTSimpleVectorIndex</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>

</pre></div>
</div>
<p>Depending on which index you use, LlamaIndex may make LLM calls in order to build the index.</p>
<div class="section" id="reusing-nodes-across-index-structures">
<h3>Reusing Nodes across Index Structures<a class="headerlink" href="#reusing-nodes-across-index-structures" title="Permalink to this heading"></a></h3>
<p>If you have multiple Node objects defined, and wish to share these Node
objects across multiple index structures, you can do that. Simply
define a DocumentStore object, add the Node objects to the DocumentStore,
and pass the DocumentStore around.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gpt_index.docstore</span> <span class="kn">import</span> <span class="n">DocumentStore</span>

<span class="n">docstore</span> <span class="o">=</span> <span class="n">DocumentStore</span><span class="p">()</span>
<span class="n">docstore</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>

<span class="n">index1</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">docstore</span><span class="o">=</span><span class="n">docstore</span><span class="p">)</span>
<span class="n">index2</span> <span class="o">=</span> <span class="n">GPTListIndex</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">docstore</span><span class="o">=</span><span class="n">docstore</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>NOTE</strong>: If the <code class="docutils literal notranslate"><span class="pre">docstore</span></code> argument isn’t specified, then it is implicitly
created for each index during index construction. You can access the docstore
associated with a given index through <code class="docutils literal notranslate"><span class="pre">index.docstore</span></code>.</p>
</div>
<div class="section" id="inserting-documents">
<h3>Inserting Documents<a class="headerlink" href="#inserting-documents" title="Permalink to this heading"></a></h3>
<p>You can also take advantage of the <code class="docutils literal notranslate"><span class="pre">insert</span></code> capability of indices to insert Document objects
one at a time instead of during index construction.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">GPTSimpleVectorIndex</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">([])</span>
<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">:</span>
    <span class="n">index</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

</pre></div>
</div>
<p>See the <a class="reference internal" href="../../how_to/index_structs/update.html"><span class="std std-doc">Update Index How-To</span></a> for details and an example notebook.</p>
<p><strong>NOTE</strong>: An <code class="docutils literal notranslate"><span class="pre">insert_node</span></code> function is coming!</p>
</div>
<div class="section" id="customizing-llm-s">
<h3>Customizing LLM’s<a class="headerlink" href="#customizing-llm-s" title="Permalink to this heading"></a></h3>
<p>By default, we use OpenAI’s <code class="docutils literal notranslate"><span class="pre">text-davinci-003</span></code> model. You may choose to use another LLM when constructing
an index.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">LLMPredictor</span><span class="p">,</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">,</span> <span class="n">PromptHelper</span><span class="p">,</span> <span class="n">ServiceContext</span>
<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="o">...</span>

<span class="c1"># define LLM</span>
<span class="n">llm_predictor</span> <span class="o">=</span> <span class="n">LLMPredictor</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">))</span>

<span class="c1"># define prompt helper</span>
<span class="c1"># set maximum input size</span>
<span class="n">max_input_size</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="c1"># set number of output tokens</span>
<span class="n">num_output</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># set maximum chunk overlap</span>
<span class="n">max_chunk_overlap</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">prompt_helper</span> <span class="o">=</span> <span class="n">PromptHelper</span><span class="p">(</span><span class="n">max_input_size</span><span class="p">,</span> <span class="n">num_output</span><span class="p">,</span> <span class="n">max_chunk_overlap</span><span class="p">)</span>

<span class="n">service_context</span> <span class="o">=</span> <span class="n">ServiceContext</span><span class="o">.</span><span class="n">from_defaults</span><span class="p">(</span><span class="n">llm_predictor</span><span class="o">=</span><span class="n">llm_predictor</span><span class="p">,</span> <span class="n">prompt_helper</span><span class="o">=</span><span class="n">prompt_helper</span><span class="p">)</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span>
    <span class="n">documents</span><span class="p">,</span> <span class="n">service_context</span><span class="o">=</span><span class="n">service_context</span>
<span class="p">)</span>
</pre></div>
</div>
<p>See the <a class="reference internal" href="../../how_to/customization/custom_llms.html"><span class="std std-doc">Custom LLM’s How-To</span></a> for more details.</p>
</div>
<div class="section" id="customizing-prompts">
<h3>Customizing Prompts<a class="headerlink" href="#customizing-prompts" title="Permalink to this heading"></a></h3>
<p>Depending on the index used, we used default prompt templates for constructing the index (and also insertion/querying).
See <a class="reference internal" href="../../how_to/customization/custom_prompts.html"><span class="std std-doc">Custom Prompts How-To</span></a> for more details on how to customize your prompt.</p>
</div>
<div class="section" id="customizing-embeddings">
<h3>Customizing embeddings<a class="headerlink" href="#customizing-embeddings" title="Permalink to this heading"></a></h3>
<p>For embedding-based indices, you can choose to pass in a custom embedding model. See
<a class="reference internal" href="../../how_to/customization/embeddings.html#custom-embeddings"><span class="std std-ref">Custom Embeddings How-To</span></a> for more details.</p>
</div>
<div class="section" id="cost-predictor">
<h3>Cost Predictor<a class="headerlink" href="#cost-predictor" title="Permalink to this heading"></a></h3>
<p>Creating an index, inserting to an index, and querying an index may use tokens. We can track
token usage through the outputs of these operations. When running operations,
the token usage will be printed.
You can also fetch the token usage through <code class="docutils literal notranslate"><span class="pre">index.llm_predictor.last_token_usage</span></code>.
See <a class="reference internal" href="../../how_to/analysis/cost_analysis.html"><span class="std std-doc">Cost Predictor How-To</span></a> for more details.</p>
</div>
<div class="section" id="optional-save-the-index-for-future-use">
<h3>[Optional] Save the index for future use<a class="headerlink" href="#optional-save-the-index-for-future-use" title="Permalink to this heading"></a></h3>
<p>To save to disk and load from disk, do</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># save to disk</span>
<span class="n">index</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="s1">&#39;index.json&#39;</span><span class="p">)</span>
<span class="c1"># load from disk</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">load_from_disk</span><span class="p">(</span><span class="s1">&#39;index.json&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>NOTE</strong>: If you had initialized the index with a custom
<code class="docutils literal notranslate"><span class="pre">ServiceContext</span></code> object, you will also need to pass in the same
ServiceContext during <code class="docutils literal notranslate"><span class="pre">load_from_disk</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">service_context</span> <span class="o">=</span> <span class="n">ServiceContext</span><span class="o">.</span><span class="n">from_defaults</span><span class="p">(</span><span class="n">llm_predictor</span><span class="o">=</span><span class="n">llm_predictor</span><span class="p">)</span>

<span class="c1"># when first building the index</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">service_context</span><span class="o">=</span><span class="n">service_context</span><span class="p">)</span>

<span class="o">...</span>

<span class="c1"># when loading the index from disk</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">load_from_disk</span><span class="p">(</span><span class="s2">&quot;index.json&quot;</span><span class="p">,</span> <span class="n">service_context</span><span class="o">=</span><span class="n">service_context</span><span class="p">)</span>

</pre></div>
</div>
</div>
</div>
<div class="section" id="optional-advanced-building-indices-on-top-of-other-indices">
<h2>4. [Optional, Advanced] Building indices on top of other indices<a class="headerlink" href="#optional-advanced-building-indices-on-top-of-other-indices" title="Permalink to this heading"></a></h2>
<p>You can build indices on top of other indices!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">,</span> <span class="n">GPTListIndex</span>

<span class="n">index1</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents1</span><span class="p">)</span>
<span class="n">index2</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents2</span><span class="p">)</span>

<span class="c1"># Set summary text</span>
<span class="c1"># you can set the summary manually, or you can</span>
<span class="c1"># generate the summary itself using LlamaIndex</span>
<span class="n">index1</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;summary1&quot;</span><span class="p">)</span>
<span class="n">index2</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;summary2&quot;</span><span class="p">)</span>

<span class="n">index3</span> <span class="o">=</span> <span class="n">GPTListIndex</span><span class="p">([</span><span class="n">index1</span><span class="p">,</span> <span class="n">index2</span><span class="p">])</span>

</pre></div>
</div>
<p>Composability gives you greater power in indexing your heterogeneous sources of data. For a discussion on relevant use cases,
see our <a class="reference internal" href="../../use_cases/queries.html"><span class="std std-doc">Query Use Cases</span></a>. For technical details and examples, see our <a class="reference internal" href="../../how_to/index_structs/composability.html"><span class="std std-doc">Composability How-To</span></a>.</p>
</div>
<div class="section" id="query-the-index">
<h2>5. Query the index.<a class="headerlink" href="#query-the-index" title="Permalink to this heading"></a></h2>
<p>After building the index, you can now query it. Note that a “query” is simply an input to an LLM -
this means that you can use the index for question-answering, but you can also do more than that!</p>
<p>To start, you can query an index without specifying any additional keyword arguments, as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;What did the author do growing up?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;Write an email to the user given their background information.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</pre></div>
</div>
<p>However, you also have a variety of keyword arguments at your disposal, depending on the type of
index being used. A full treatment of all the index-dependent query keyword arguments can be
found <a class="reference internal" href="../../reference/query.html"><span class="std std-doc">here</span></a>.</p>
<div class="section" id="setting-mode">
<h3>Setting <code class="docutils literal notranslate"><span class="pre">mode</span></code><a class="headerlink" href="#setting-mode" title="Permalink to this heading"></a></h3>
<p>An index can have a variety of query modes. For instance, you can choose to specify
<code class="docutils literal notranslate"><span class="pre">mode=&quot;default&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">mode=&quot;embedding&quot;</span></code> for a list index. <code class="docutils literal notranslate"><span class="pre">mode=&quot;default&quot;</span></code> will a
create and refine an answer sequentially through the nodes of the list.
<code class="docutils literal notranslate"><span class="pre">mode=&quot;embedding&quot;</span></code> will synthesize an answer by fetching the top-k
nodes by embedding similarity.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">GPTListIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
<span class="c1"># mode=&quot;default&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;What did the author do growing up?&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">)</span>
<span class="c1"># mode=&quot;embedding&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;What did the author do growing up?&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;embedding&quot;</span><span class="p">)</span>

</pre></div>
</div>
<p>The full set of modes per index are documented in the <a class="reference internal" href="../../reference/query.html"><span class="std std-doc">Query Reference</span></a>.</p>
</div>
<div class="section" id="setting-response-mode">
<span id="id1"></span><h3>Setting <code class="docutils literal notranslate"><span class="pre">response_mode</span></code><a class="headerlink" href="#setting-response-mode" title="Permalink to this heading"></a></h3>
<p>Note: This option is not available/utilized in <code class="docutils literal notranslate"><span class="pre">GPTTreeIndex</span></code>.</p>
<p>An index can also have the following response modes through <code class="docutils literal notranslate"><span class="pre">response_mode</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">default</span></code>: For the given index, “create and refine” an answer by sequentially going through each Node;
make a separate LLM call per Node. Good for more detailed answers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compact</span></code>: For the given index, “compact” the prompt during each LLM call by stuffing as
many Node text chunks that can fit within the maximum prompt size. If there are
too many chunks to stuff in one prompt, “create and refine” an answer by going through
multiple prompts.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tree_summarize</span></code>: Given a set of Nodes and the query, recursively construct a tree
and return the root node as the response. Good for summarization purposes.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">GPTListIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
<span class="c1"># mode=&quot;default&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;What did the author do growing up?&quot;</span><span class="p">,</span> <span class="n">response_mode</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">)</span>
<span class="c1"># mode=&quot;compact&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;What did the author do growing up?&quot;</span><span class="p">,</span> <span class="n">response_mode</span><span class="o">=</span><span class="s2">&quot;compact&quot;</span><span class="p">)</span>
<span class="c1"># mode=&quot;tree_summarize&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;What did the author do growing up?&quot;</span><span class="p">,</span> <span class="n">response_mode</span><span class="o">=</span><span class="s2">&quot;tree_summarize&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="setting-required-keywords-and-exclude-keywords">
<h3>Setting <code class="docutils literal notranslate"><span class="pre">required_keywords</span></code> and <code class="docutils literal notranslate"><span class="pre">exclude_keywords</span></code><a class="headerlink" href="#setting-required-keywords-and-exclude-keywords" title="Permalink to this heading"></a></h3>
<p>You can set <code class="docutils literal notranslate"><span class="pre">required_keywords</span></code> and <code class="docutils literal notranslate"><span class="pre">exclude_keywords</span></code> on most of our indices (the only exclusion is the GPTTreeIndex). This will preemptively filter out nodes that do not contain <code class="docutils literal notranslate"><span class="pre">required_keywords</span></code> or contain <code class="docutils literal notranslate"><span class="pre">exclude_keywords</span></code>, reducing the search space
and hence time/number of LLM calls/cost.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span>
    <span class="s2">&quot;What did the author do after Y Combinator?&quot;</span><span class="p">,</span> <span class="n">required_keywords</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Combinator&quot;</span><span class="p">],</span> 
    <span class="n">exclude_keywords</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Italy&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="parsing-the-response">
<h2>5. Parsing the response<a class="headerlink" href="#parsing-the-response" title="Permalink to this heading"></a></h2>
<p>The object returned is a <a class="reference internal" href="../../reference/response.html"><span class="std std-doc"><code class="docutils literal notranslate"><span class="pre">Response</span></code> object</span></a>.
The object contains both the response text as well as the “sources” of the response:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;&lt;query_str&gt;&quot;</span><span class="p">)</span>

<span class="c1"># get response</span>
<span class="c1"># response.response</span>
<span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

<span class="c1"># get sources</span>
<span class="n">response</span><span class="o">.</span><span class="n">source_nodes</span>
<span class="c1"># formatted sources</span>
<span class="n">response</span><span class="o">.</span><span class="n">get_formatted_sources</span><span class="p">()</span>
</pre></div>
</div>
<p>An example is shown below.
<img alt="" src="../../_images/response_1.jpeg" /></p>
</div>
</div>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="index_guide.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">How Each Index Works</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../primer.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">A Primer to using LlamaIndex</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Jerry Liu
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link" href="https://readthedocs.org/projects/gpt-index" aria-label="On Read the Docs">
                <svg x="0px" y="0px" viewBox="-125 217 360 360" xml:space="preserve">
                  <path fill="currentColor" d="M39.2,391.3c-4.2,0.6-7.1,4.4-6.5,8.5c0.4,3,2.6,5.5,5.5,6.3 c0,0,18.5,6.1,50,8.7c25.3,2.1,54-1.8,54-1.8c4.2-0.1,7.5-3.6,7.4-7.8c-0.1-4.2-3.6-7.5-7.8-7.4c-0.5,0-1,0.1-1.5,0.2 c0,0-28.1,3.5-50.9,1.6c-30.1-2.4-46.5-7.9-46.5-7.9C41.7,391.3,40.4,391.1,39.2,391.3z M39.2,353.6c-4.2,0.6-7.1,4.4-6.5,8.5 c0.4,3,2.6,5.5,5.5,6.3c0,0,18.5,6.1,50,8.7c25.3,2.1,54-1.8,54-1.8c4.2-0.1,7.5-3.6,7.4-7.8c-0.1-4.2-3.6-7.5-7.8-7.4 c-0.5,0-1,0.1-1.5,0.2c0,0-28.1,3.5-50.9,1.6c-30.1-2.4-46.5-7.9-46.5-7.9C41.7,353.6,40.4,353.4,39.2,353.6z M39.2,315.9 c-4.2,0.6-7.1,4.4-6.5,8.5c0.4,3,2.6,5.5,5.5,6.3c0,0,18.5,6.1,50,8.7c25.3,2.1,54-1.8,54-1.8c4.2-0.1,7.5-3.6,7.4-7.8 c-0.1-4.2-3.6-7.5-7.8-7.4c-0.5,0-1,0.1-1.5,0.2c0,0-28.1,3.5-50.9,1.6c-30.1-2.4-46.5-7.9-46.5-7.9 C41.7,315.9,40.4,315.8,39.2,315.9z M39.2,278.3c-4.2,0.6-7.1,4.4-6.5,8.5c0.4,3,2.6,5.5,5.5,6.3c0,0,18.5,6.1,50,8.7 c25.3,2.1,54-1.8,54-1.8c4.2-0.1,7.5-3.6,7.4-7.8c-0.1-4.2-3.6-7.5-7.8-7.4c-0.5,0-1,0.1-1.5,0.2c0,0-28.1,3.5-50.9,1.6 c-30.1-2.4-46.5-7.9-46.5-7.9C41.7,278.2,40.4,278.1,39.2,278.3z M-13.6,238.5c-39.6,0.3-54.3,12.5-54.3,12.5v295.7 c0,0,14.4-12.4,60.8-10.5s55.9,18.2,112.9,19.3s71.3-8.8,71.3-8.8l0.8-301.4c0,0-25.6,7.3-75.6,7.7c-49.9,0.4-61.9-12.7-107.7-14.2 C-8.2,238.6-10.9,238.5-13.6,238.5z M19.5,257.8c0,0,24,7.9,68.3,10.1c37.5,1.9,75-3.7,75-3.7v267.9c0,0-19,10-66.5,6.6 C59.5,536.1,19,522.1,19,522.1L19.5,257.8z M-3.6,264.8c4.2,0,7.7,3.4,7.7,7.7c0,4.2-3.4,7.7-7.7,7.7c0,0-12.4,0.1-20,0.8 c-12.7,1.3-21.4,5.9-21.4,5.9c-3.7,2-8.4,0.5-10.3-3.2c-2-3.7-0.5-8.4,3.2-10.3c0,0,0,0,0,0c0,0,11.3-6,27-7.5 C-16,264.9-3.6,264.8-3.6,264.8z M-11,302.6c4.2-0.1,7.4,0,7.4,0c4.2,0.5,7.2,4.3,6.7,8.5c-0.4,3.5-3.2,6.3-6.7,6.7 c0,0-12.4,0.1-20,0.8c-12.7,1.3-21.4,5.9-21.4,5.9c-3.7,2-8.4,0.5-10.3-3.2c-2-3.7-0.5-8.4,3.2-10.3c0,0,11.3-6,27-7.5 C-20.5,302.9-15.2,302.7-11,302.6z M-3.6,340.2c4.2,0,7.7,3.4,7.7,7.7s-3.4,7.7-7.7,7.7c0,0-12.4-0.1-20,0.7 c-12.7,1.3-21.4,5.9-21.4,5.9c-3.7,2-8.4,0.5-10.3-3.2c-2-3.7-0.5-8.4,3.2-10.3c0,0,11.3-6,27-7.5C-16,340.1-3.6,340.2-3.6,340.2z" />
                </svg>
              </a><a class="muted-link" href="https://github.com/jerryjliu/gpt_index" aria-label="On GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                  <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
              </a>
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">LlamaIndex Usage Pattern</a><ul>
<li><a class="reference internal" href="#load-in-documents">1. Load in Documents</a></li>
<li><a class="reference internal" href="#parse-the-documents-into-nodes">2. Parse the Documents into Nodes</a></li>
<li><a class="reference internal" href="#index-construction">3. Index Construction</a><ul>
<li><a class="reference internal" href="#reusing-nodes-across-index-structures">Reusing Nodes across Index Structures</a></li>
<li><a class="reference internal" href="#inserting-documents">Inserting Documents</a></li>
<li><a class="reference internal" href="#customizing-llm-s">Customizing LLM’s</a></li>
<li><a class="reference internal" href="#customizing-prompts">Customizing Prompts</a></li>
<li><a class="reference internal" href="#customizing-embeddings">Customizing embeddings</a></li>
<li><a class="reference internal" href="#cost-predictor">Cost Predictor</a></li>
<li><a class="reference internal" href="#optional-save-the-index-for-future-use">[Optional] Save the index for future use</a></li>
</ul>
</li>
<li><a class="reference internal" href="#optional-advanced-building-indices-on-top-of-other-indices">4. [Optional, Advanced] Building indices on top of other indices</a></li>
<li><a class="reference internal" href="#query-the-index">5. Query the index.</a><ul>
<li><a class="reference internal" href="#setting-mode">Setting <code class="docutils literal notranslate"><span class="pre">mode</span></code></a></li>
<li><a class="reference internal" href="#setting-response-mode">Setting <code class="docutils literal notranslate"><span class="pre">response_mode</span></code></a></li>
<li><a class="reference internal" href="#setting-required-keywords-and-exclude-keywords">Setting <code class="docutils literal notranslate"><span class="pre">required_keywords</span></code> and <code class="docutils literal notranslate"><span class="pre">exclude_keywords</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#parsing-the-response">5. Parsing the response</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script async="async" src="/_/static/javascript/readthedocs-doc-embed.js"></script>
    <script src="../../_static/js/mendablesearch.js"></script>
    </body>
</html>
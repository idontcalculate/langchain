{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /home/cloudsuperadmin/.local/lib/python3.9/site-packages (12.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/openai/whisper.git\n",
    "! pip install jiwer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JiWER is a simple and fast python package to evaluate an automatic speech recognition system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY =os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "link='https://www.youtube.com/watch?v=mBjPyte2ZZo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # object creation using YouTube\n",
    "    yt = YouTube(link) \n",
    "except: \n",
    "    print(\"Connection Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.streams.filter(file_extension='mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = yt.streams.get_by_itag(139)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cloudsuperadmin/scrape-chain/lecuninterview.mp4'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.download('',\"lecuninterview.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"/home/cloudsuperadmin/scrape-chain/lecuninterview.mp4\")\n",
    "print(result['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got the result in a form of a raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('text.txt', 'w') as file:  \n",
    "    file.write(result['text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt') as f:\n",
    "    text = f.read()\n",
    "texts = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Hi, I'm Craig Smith and this is I on A On. This week I talked to Jan LeCoon, one of the seminal figures in deep learning development and a long time proponent of self-supervised learning. Jan spoke about what's missing in large language models and about his new joint embedding predictive architecture which may be a step toward filling that gap. He also talked about his theory of consciousness and the potential for AI systems to someday exhibit the features of consciousness. It's a fascinating conversation that I hope you'll enjoy. Okay, so Jan, it's great to see you again. Good to see you again. I wanted to talk to you about where you've gone with just so supervised learning since last week spoke. In particular, I'm interested in how it relates to large language models because the large language models really came on stream since we spoke. In fact, in your talk about JEPA, which is joint embedding predictive architecture. Thank you. You mentioned that large language models lack a\", metadata={}),\n",
       " Document(page_content=\"world model. I wanted to talk first about where you've gone with self-supervised learning and where this latest paper stands for your trajectory. But to start, if you could just introduce yourself and we'll go from there. Okay, so my name is Jan Le Ka or Jan Le Kun who want to do it in Gilleswee. And I'm a professor at New York University and at the Guarante Institute in the Centre for Data Science. And I'm also the chief AI scientist at Fair, which is the fundamental AI research lab. That's what Fair stands for. Admetta, Neil, Facebook. So tell me about where you've gone with self-supervised learning, how the joint embedding predictive architecture fits into your research. And then if you could talk about how that relates to what's lacking in large language models. Okay, self-supervised learning has basically brought about a revolution in natural language processing because of their use for pre-training transformer architectures. And the fact that we use transformer architectures for\", metadata={}),\n",
       " Document(page_content=\"that is somewhat orthogonal to the fact that we use self-supervised learning. But the way those systems are trained is that you take a piece of text, you remove some of the words, you replace them by black markers. And then you train the very large neural net to predict the words that are missing. That's a pre-training phase. And then in the process of training itself to do this, the system learns good representations of text that you can then use as input to its subsequent downstream task, I don't know, translation or hitch-pitch detection or something like that. So that's been a two-year revolution over the last three or four years. And including in sort of very practical applications like every sort of top-performing contact moderation systems on Facebook, Google, YouTube, etc. Use this kind of technique. And there's all kinds of other applications. Now, large language models are partially this, but also the idea that you can train those things to just predict the next word in a\", metadata={}),\n",
       " Document(page_content=\"text. And if you use that, you can have those system generate text spontaneously. So there's a few issues with this. First of all, those things are what's called generative models in the sense that they predict the words, the information that is missing, words in this case. And the problem with generative models is that it's very difficult to represent uncertain predictions. So in the case of words, it's easy because we just have the system produce essentially what amounts to a score or a probability for every word in the dictionary. And so it cannot tell you if the word missing in a sentence like the blank chases the mouse in the kitchen. It's probably a cat, it could be a dog, but it's probably a cat, right? So you have some distribution of probability over all words in the dictionary. And you can handle uncertainty in the prediction this way. But then what if you want to apply this to, let's say, video, right? So you show a video to the system, you remove some of the frames in that\", metadata={})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Craig Smith interviews Jan LeCoon, a deep learning developer and proponent of self-supervised\n",
      "learning, about his new joint embedding predictive architecture and his theory of consciousness.\n",
      "Jan's research focuses on self-supervised learning and its use for pre-training transformer\n",
      "architectures, which is used to predict missing words in a piece of text. Additionally, large\n",
      "language models are used to predict the next word in a sentence, but it is difficult to represent\n",
      "uncertain predictions when applying this to video.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"map_reduce\")\n",
    "\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise bullet point summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "CONSCISE SUMMARY IN BULLET POINTS: AND TRANSLATE IT TO FRENCH\"\"\"\n",
    "\n",
    "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template, \n",
    "                        input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "• Jan LeCoon is a seminal figure in deep learning development and a long-time proponent of self-supervised learning. \n",
      "• He discussed his new joint embedding predictive architecture which may be a step towards filling the gap in large language models. \n",
      "• He also discussed his theory of consciousness and the potential for AI systems to someday exhibit the features of consciousness. \n",
      "• Self-supervised learning has revolutionized natural language processing by using transformer architectures for pre-training. \n",
      "• Large language models lack a world model and are generative models, making it difficult to represent uncertain predictions. \n",
      "\n",
      "• Jan LeCoon est une figure emblématique du développement d'apprentissage profond et un partisan de longue date de l'apprentissage supervisé. \n",
      "• Il a discuté de sa nouvelle architecture d'apprentissage prédictif d'intégration conjointe qui pourrait être une étape vers le remplissage de l'écart dans les grands modèles de langage. \n",
      "• Il a également discuté de sa théorie de\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"stuff\", \n",
    "                             prompt=BULLET_POINT_PROMPT)\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "\n",
    "wrapped_text = textwrap.fill(output_summary, \n",
    "                             width=2000,\n",
    "                             break_long_words=False,\n",
    "                             replace_whitespace=False)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Craig Smith interviews Jan LeCoon, a deep learning developer and proponent of self-supervised\n",
      "learning, about his new joint embedding predictive architecture and his theory of consciousness. Jan\n",
      "discusses how large language models are missing something and how his architecture may be a step\n",
      "towards filling that gap, as well as the potential for AI systems to exhibit features of\n",
      "consciousness. Jan has gone on to revolutionize natural language processing with self-supervised\n",
      "learning and transformer architectures, and explains how his joint embedding predictive architecture\n",
      "fits into his research and how it relates to what's lacking in large language models. He explains\n",
      "that self-supervised learning involves taking a piece of text, removing some of the words, and\n",
      "replacing them with black markers, then training a neural net to predict the words that are missing.\n",
      "This technique has been used in practical applications such as contact moderation systems on\n",
      "Facebook, Google, YouTube, etc. and has been a two-year revolution over the last three or four\n",
      "years. Large language models are partially this, but also the idea that they can be trained to\n",
      "predict the next word in a sentence. Jan further explains that this technique can be used to\n",
      "generate text spontaneously, but there are issues with representing uncertain predictions. He also\n",
      "discusses how this technique can be applied to\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
